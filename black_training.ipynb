{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'omokdataset' from 'c:\\\\Users\\\\82105\\\\Desktop\\\\Omok\\\\omokdataset.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import omokdataset\n",
    "reload(omokdataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "# cuda or mps\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = 'omok_dataset'\n",
    "training_path = os.path.join('checkpoint', 'model.pth')\n",
    "who_win = 1 # 0: draw, 1: black, 2: white\n",
    "level = 0\n",
    "mode = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = omokdataset.OmokDataset(dataset_root, who_win, level, mode)\n",
    "\n",
    "split_ratio = 0.8\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, \n",
    "                                                   [int(len(train_set)*split_ratio), \n",
    "                                                    len(train_set)-int(len(train_set)*split_ratio)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.model\n",
    "reload(models.model)\n",
    "\n",
    "model = models.model.SimpleNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_meter = AverageMeter()\n",
    "tr_loss_meter = AverageMeter()\n",
    "rot_loss_meter = AverageMeter()\n",
    "\n",
    "train_loss_log = []\n",
    "train_tr_loss_log = []\n",
    "train_rot_loss_log = []\n",
    "val_loss_log = []\n",
    "val_tr_loss_log = []\n",
    "val_rot_loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "visualize_step = max(1, total_step // 10) ################### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [1/50] -------------------\n",
      "Epoch [1/50], Step [1/1], Loss: 5.4431\n",
      "==> Train loss: 5.4431\n",
      "------------------- Val: Epoch [1/50] -------------------\n",
      "Epoch [1/50], Step [1/1], Loss: 5.4478\n",
      "==> Val loss: 5.4478\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [2/50] -------------------\n",
      "Epoch [2/50], Step [1/1], Loss: 5.4390\n",
      "==> Train loss: 5.4390\n",
      "------------------- Val: Epoch [2/50] -------------------\n",
      "Epoch [2/50], Step [1/1], Loss: 5.4475\n",
      "==> Val loss: 5.4475\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [3/50] -------------------\n",
      "Epoch [3/50], Step [1/1], Loss: 5.4350\n",
      "==> Train loss: 5.4350\n",
      "------------------- Val: Epoch [3/50] -------------------\n",
      "Epoch [3/50], Step [1/1], Loss: 5.4471\n",
      "==> Val loss: 5.4471\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [4/50] -------------------\n",
      "Epoch [4/50], Step [1/1], Loss: 5.4311\n",
      "==> Train loss: 5.4311\n",
      "------------------- Val: Epoch [4/50] -------------------\n",
      "Epoch [4/50], Step [1/1], Loss: 5.4467\n",
      "==> Val loss: 5.4467\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [5/50] -------------------\n",
      "Epoch [5/50], Step [1/1], Loss: 5.4272\n",
      "==> Train loss: 5.4272\n",
      "------------------- Val: Epoch [5/50] -------------------\n",
      "Epoch [5/50], Step [1/1], Loss: 5.4464\n",
      "==> Val loss: 5.4464\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [6/50] -------------------\n",
      "Epoch [6/50], Step [1/1], Loss: 5.4234\n",
      "==> Train loss: 5.4234\n",
      "------------------- Val: Epoch [6/50] -------------------\n",
      "Epoch [6/50], Step [1/1], Loss: 5.4462\n",
      "==> Val loss: 5.4462\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [7/50] -------------------\n",
      "Epoch [7/50], Step [1/1], Loss: 5.4196\n",
      "==> Train loss: 5.4196\n",
      "------------------- Val: Epoch [7/50] -------------------\n",
      "Epoch [7/50], Step [1/1], Loss: 5.4460\n",
      "==> Val loss: 5.4460\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [8/50] -------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [1/1], Loss: 5.4158\n",
      "==> Train loss: 5.4158\n",
      "------------------- Val: Epoch [8/50] -------------------\n",
      "Epoch [8/50], Step [1/1], Loss: 5.4459\n",
      "==> Val loss: 5.4459\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [9/50] -------------------\n",
      "Epoch [9/50], Step [1/1], Loss: 5.4120\n",
      "==> Train loss: 5.4120\n",
      "------------------- Val: Epoch [9/50] -------------------\n",
      "Epoch [9/50], Step [1/1], Loss: 5.4457\n",
      "==> Val loss: 5.4457\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [10/50] -------------------\n",
      "Epoch [10/50], Step [1/1], Loss: 5.4082\n",
      "==> Train loss: 5.4082\n",
      "------------------- Val: Epoch [10/50] -------------------\n",
      "Epoch [10/50], Step [1/1], Loss: 5.4456\n",
      "==> Val loss: 5.4456\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [11/50] -------------------\n",
      "Epoch [11/50], Step [1/1], Loss: 5.4042\n",
      "==> Train loss: 5.4042\n",
      "------------------- Val: Epoch [11/50] -------------------\n",
      "Epoch [11/50], Step [1/1], Loss: 5.4455\n",
      "==> Val loss: 5.4455\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [12/50] -------------------\n",
      "Epoch [12/50], Step [1/1], Loss: 5.4002\n",
      "==> Train loss: 5.4002\n",
      "------------------- Val: Epoch [12/50] -------------------\n",
      "Epoch [12/50], Step [1/1], Loss: 5.4454\n",
      "==> Val loss: 5.4454\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [13/50] -------------------\n",
      "Epoch [13/50], Step [1/1], Loss: 5.3961\n",
      "==> Train loss: 5.3961\n",
      "------------------- Val: Epoch [13/50] -------------------\n",
      "Epoch [13/50], Step [1/1], Loss: 5.4453\n",
      "==> Val loss: 5.4453\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [14/50] -------------------\n",
      "Epoch [14/50], Step [1/1], Loss: 5.3919\n",
      "==> Train loss: 5.3919\n",
      "------------------- Val: Epoch [14/50] -------------------\n",
      "Epoch [14/50], Step [1/1], Loss: 5.4452\n",
      "==> Val loss: 5.4452\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [15/50] -------------------\n",
      "Epoch [15/50], Step [1/1], Loss: 5.3875\n",
      "==> Train loss: 5.3875\n",
      "------------------- Val: Epoch [15/50] -------------------\n",
      "Epoch [15/50], Step [1/1], Loss: 5.4452\n",
      "==> Val loss: 5.4452\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [16/50] -------------------\n",
      "Epoch [16/50], Step [1/1], Loss: 5.3830\n",
      "==> Train loss: 5.3830\n",
      "------------------- Val: Epoch [16/50] -------------------\n",
      "Epoch [16/50], Step [1/1], Loss: 5.4452\n",
      "==> Val loss: 5.4452\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [17/50] -------------------\n",
      "Epoch [17/50], Step [1/1], Loss: 5.3783\n",
      "==> Train loss: 5.3783\n",
      "------------------- Val: Epoch [17/50] -------------------\n",
      "Epoch [17/50], Step [1/1], Loss: 5.4453\n",
      "==> Val loss: 5.4453\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [18/50] -------------------\n",
      "Epoch [18/50], Step [1/1], Loss: 5.3733\n",
      "==> Train loss: 5.3733\n",
      "------------------- Val: Epoch [18/50] -------------------\n",
      "Epoch [18/50], Step [1/1], Loss: 5.4454\n",
      "==> Val loss: 5.4454\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [19/50] -------------------\n",
      "Epoch [19/50], Step [1/1], Loss: 5.3680\n",
      "==> Train loss: 5.3680\n",
      "------------------- Val: Epoch [19/50] -------------------\n",
      "Epoch [19/50], Step [1/1], Loss: 5.4456\n",
      "==> Val loss: 5.4456\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [20/50] -------------------\n",
      "Epoch [20/50], Step [1/1], Loss: 5.3625\n",
      "==> Train loss: 5.3625\n",
      "------------------- Val: Epoch [20/50] -------------------\n",
      "Epoch [20/50], Step [1/1], Loss: 5.4458\n",
      "==> Val loss: 5.4458\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [21/50] -------------------\n",
      "Epoch [21/50], Step [1/1], Loss: 5.3565\n",
      "==> Train loss: 5.3565\n",
      "------------------- Val: Epoch [21/50] -------------------\n",
      "Epoch [21/50], Step [1/1], Loss: 5.4461\n",
      "==> Val loss: 5.4461\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [22/50] -------------------\n",
      "Epoch [22/50], Step [1/1], Loss: 5.3501\n",
      "==> Train loss: 5.3501\n",
      "------------------- Val: Epoch [22/50] -------------------\n",
      "Epoch [22/50], Step [1/1], Loss: 5.4462\n",
      "==> Val loss: 5.4462\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [23/50] -------------------\n",
      "Epoch [23/50], Step [1/1], Loss: 5.3432\n",
      "==> Train loss: 5.3432\n",
      "------------------- Val: Epoch [23/50] -------------------\n",
      "Epoch [23/50], Step [1/1], Loss: 5.4464\n",
      "==> Val loss: 5.4464\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [24/50] -------------------\n",
      "Epoch [24/50], Step [1/1], Loss: 5.3355\n",
      "==> Train loss: 5.3355\n",
      "------------------- Val: Epoch [24/50] -------------------\n",
      "Epoch [24/50], Step [1/1], Loss: 5.4463\n",
      "==> Val loss: 5.4463\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [25/50] -------------------\n",
      "Epoch [25/50], Step [1/1], Loss: 5.3270\n",
      "==> Train loss: 5.3270\n",
      "------------------- Val: Epoch [25/50] -------------------\n",
      "Epoch [25/50], Step [1/1], Loss: 5.4461\n",
      "==> Val loss: 5.4461\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [26/50] -------------------\n",
      "Epoch [26/50], Step [1/1], Loss: 5.3174\n",
      "==> Train loss: 5.3174\n",
      "------------------- Val: Epoch [26/50] -------------------\n",
      "Epoch [26/50], Step [1/1], Loss: 5.4458\n",
      "==> Val loss: 5.4458\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [27/50] -------------------\n",
      "Epoch [27/50], Step [1/1], Loss: 5.3066\n",
      "==> Train loss: 5.3066\n",
      "------------------- Val: Epoch [27/50] -------------------\n",
      "Epoch [27/50], Step [1/1], Loss: 5.4457\n",
      "==> Val loss: 5.4457\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [28/50] -------------------\n",
      "Epoch [28/50], Step [1/1], Loss: 5.2943\n",
      "==> Train loss: 5.2943\n",
      "------------------- Val: Epoch [28/50] -------------------\n",
      "Epoch [28/50], Step [1/1], Loss: 5.4457\n",
      "==> Val loss: 5.4457\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [29/50] -------------------\n",
      "Epoch [29/50], Step [1/1], Loss: 5.2804\n",
      "==> Train loss: 5.2804\n",
      "------------------- Val: Epoch [29/50] -------------------\n",
      "Epoch [29/50], Step [1/1], Loss: 5.4457\n",
      "==> Val loss: 5.4457\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [30/50] -------------------\n",
      "Epoch [30/50], Step [1/1], Loss: 5.2647\n",
      "==> Train loss: 5.2647\n",
      "------------------- Val: Epoch [30/50] -------------------\n",
      "Epoch [30/50], Step [1/1], Loss: 5.4457\n",
      "==> Val loss: 5.4457\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [31/50] -------------------\n",
      "Epoch [31/50], Step [1/1], Loss: 5.2466\n",
      "==> Train loss: 5.2466\n",
      "------------------- Val: Epoch [31/50] -------------------\n",
      "Epoch [31/50], Step [1/1], Loss: 5.4463\n",
      "==> Val loss: 5.4463\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [32/50] -------------------\n",
      "Epoch [32/50], Step [1/1], Loss: 5.2262\n",
      "==> Train loss: 5.2262\n",
      "------------------- Val: Epoch [32/50] -------------------\n",
      "Epoch [32/50], Step [1/1], Loss: 5.4472\n",
      "==> Val loss: 5.4472\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [33/50] -------------------\n",
      "Epoch [33/50], Step [1/1], Loss: 5.2023\n",
      "==> Train loss: 5.2023\n",
      "------------------- Val: Epoch [33/50] -------------------\n",
      "Epoch [33/50], Step [1/1], Loss: 5.4485\n",
      "==> Val loss: 5.4485\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [34/50] -------------------\n",
      "Epoch [34/50], Step [1/1], Loss: 5.1745\n",
      "==> Train loss: 5.1745\n",
      "------------------- Val: Epoch [34/50] -------------------\n",
      "Epoch [34/50], Step [1/1], Loss: 5.4503\n",
      "==> Val loss: 5.4503\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [35/50] -------------------\n",
      "Epoch [35/50], Step [1/1], Loss: 5.1422\n",
      "==> Train loss: 5.1422\n",
      "------------------- Val: Epoch [35/50] -------------------\n",
      "Epoch [35/50], Step [1/1], Loss: 5.4524\n",
      "==> Val loss: 5.4524\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [36/50] -------------------\n",
      "Epoch [36/50], Step [1/1], Loss: 5.1046\n",
      "==> Train loss: 5.1046\n",
      "------------------- Val: Epoch [36/50] -------------------\n",
      "Epoch [36/50], Step [1/1], Loss: 5.4547\n",
      "==> Val loss: 5.4547\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [37/50] -------------------\n",
      "Epoch [37/50], Step [1/1], Loss: 5.0603\n",
      "==> Train loss: 5.0603\n",
      "------------------- Val: Epoch [37/50] -------------------\n",
      "Epoch [37/50], Step [1/1], Loss: 5.4575\n",
      "==> Val loss: 5.4575\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [38/50] -------------------\n",
      "Epoch [38/50], Step [1/1], Loss: 5.0078\n",
      "==> Train loss: 5.0078\n",
      "------------------- Val: Epoch [38/50] -------------------\n",
      "Epoch [38/50], Step [1/1], Loss: 5.4607\n",
      "==> Val loss: 5.4607\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [39/50] -------------------\n",
      "Epoch [39/50], Step [1/1], Loss: 4.9459\n",
      "==> Train loss: 4.9459\n",
      "------------------- Val: Epoch [39/50] -------------------\n",
      "Epoch [39/50], Step [1/1], Loss: 5.4653\n",
      "==> Val loss: 5.4653\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [40/50] -------------------\n",
      "Epoch [40/50], Step [1/1], Loss: 4.8730\n",
      "==> Train loss: 4.8730\n",
      "------------------- Val: Epoch [40/50] -------------------\n",
      "Epoch [40/50], Step [1/1], Loss: 5.4713\n",
      "==> Val loss: 5.4713\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [41/50] -------------------\n",
      "Epoch [41/50], Step [1/1], Loss: 4.7873\n",
      "==> Train loss: 4.7873\n",
      "------------------- Val: Epoch [41/50] -------------------\n",
      "Epoch [41/50], Step [1/1], Loss: 5.4786\n",
      "==> Val loss: 5.4786\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [42/50] -------------------\n",
      "Epoch [42/50], Step [1/1], Loss: 4.6863\n",
      "==> Train loss: 4.6863\n",
      "------------------- Val: Epoch [42/50] -------------------\n",
      "Epoch [42/50], Step [1/1], Loss: 5.4874\n",
      "==> Val loss: 5.4874\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [43/50] -------------------\n",
      "Epoch [43/50], Step [1/1], Loss: 4.5681\n",
      "==> Train loss: 4.5681\n",
      "------------------- Val: Epoch [43/50] -------------------\n",
      "Epoch [43/50], Step [1/1], Loss: 5.4979\n",
      "==> Val loss: 5.4979\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [44/50] -------------------\n",
      "Epoch [44/50], Step [1/1], Loss: 4.4293\n",
      "==> Train loss: 4.4293\n",
      "------------------- Val: Epoch [44/50] -------------------\n",
      "Epoch [44/50], Step [1/1], Loss: 5.5101\n",
      "==> Val loss: 5.5101\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [45/50] -------------------\n",
      "Epoch [45/50], Step [1/1], Loss: 4.2663\n",
      "==> Train loss: 4.2663\n",
      "------------------- Val: Epoch [45/50] -------------------\n",
      "Epoch [45/50], Step [1/1], Loss: 5.5244\n",
      "==> Val loss: 5.5244\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [46/50] -------------------\n",
      "Epoch [46/50], Step [1/1], Loss: 4.0753\n",
      "==> Train loss: 4.0753\n",
      "------------------- Val: Epoch [46/50] -------------------\n",
      "Epoch [46/50], Step [1/1], Loss: 5.5409\n",
      "==> Val loss: 5.5409\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [47/50] -------------------\n",
      "Epoch [47/50], Step [1/1], Loss: 3.8521\n",
      "==> Train loss: 3.8521\n",
      "------------------- Val: Epoch [47/50] -------------------\n",
      "Epoch [47/50], Step [1/1], Loss: 5.5611\n",
      "==> Val loss: 5.5611\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [48/50] -------------------\n",
      "Epoch [48/50], Step [1/1], Loss: 3.5926\n",
      "==> Train loss: 3.5926\n",
      "------------------- Val: Epoch [48/50] -------------------\n",
      "Epoch [48/50], Step [1/1], Loss: 5.5864\n",
      "==> Val loss: 5.5864\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [49/50] -------------------\n",
      "Epoch [49/50], Step [1/1], Loss: 3.2928\n",
      "==> Train loss: 3.2928\n",
      "------------------- Val: Epoch [49/50] -------------------\n",
      "Epoch [49/50], Step [1/1], Loss: 5.6198\n",
      "==> Val loss: 5.6198\n",
      "learing rage:  0.0001\n",
      "------------------- Train: Epoch [50/50] -------------------\n",
      "Epoch [50/50], Step [1/1], Loss: 2.9508\n",
      "==> Train loss: 2.9508\n",
      "------------------- Val: Epoch [50/50] -------------------\n",
      "Epoch [50/50], Step [1/1], Loss: 5.6638\n",
      "==> Val loss: 5.6638\n",
      "best model updated\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 1e10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('learing rage: ', param_group['lr'])\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    print ('------------------- Train: Epoch [{}/{}] -------------------'.format(\\\n",
    "        epoch+1, num_epochs) )\n",
    "\n",
    "    loss_meter.reset()\n",
    "\n",
    "    for i, (board_status, target) in enumerate(train_loader):\n",
    "        board_status = board_status.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        board_status = board_status.type(torch.float32)\n",
    "        pred = model(board_status)\n",
    "        loss = loss_fn(pred, target)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # logging\n",
    "        loss_meter.update(loss.item(), board_status.size()[0] )\n",
    "\n",
    "        if (i+1) % visualize_step == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\\\n",
    "                epoch+1, num_epochs, i+1, total_step, loss.item() ) )\n",
    "\n",
    "    print ('==> Train loss: {:.4f}'.format(loss_meter.avg) )\n",
    "\n",
    "    train_loss_log.append(loss_meter.avg)\n",
    "\n",
    "    # val\n",
    "    model.eval() \n",
    "    print ('------------------- Val: Epoch [{}/{}] -------------------'.format(\\\n",
    "        epoch+1, num_epochs) ) \n",
    "    \n",
    "    loss_meter.reset()\n",
    "\n",
    "    for i, (board_status, target) in enumerate(val_loader):\n",
    "        board_status = board_status.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        board_status = board_status.type(torch.float32)\n",
    "        pred = model(board_status)\n",
    "        loss = loss_fn(pred, target)\n",
    "\n",
    "        # logging\n",
    "        loss_meter.update(loss.item(), board_status.size()[0] )\n",
    "\n",
    "        if (i+1) % visualize_step == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\\\n",
    "                epoch+1, num_epochs, i+1, total_step, loss.item() ) )\n",
    "            \n",
    "    print ('==> Val loss: {:.4f}'.format(loss_meter.avg) )\n",
    "\n",
    "    val_loss_log.append(loss_meter.avg)\n",
    "    # save model\n",
    "    if loss_meter.avg < best_val_loss:\n",
    "        best_val_loss = loss_meter.avg\n",
    "        if not os.path.exists('checkpoint'):\n",
    "            os.makedirs('checkpoint')\n",
    "        torch.save(model.state_dict(), 'checkpoint/best.pth')\n",
    "\n",
    "# save best model\n",
    "if not os.path.exists(training_path):\n",
    "    print('best model updated')\n",
    "    checkpoint = {\n",
    "        'model': torch.load('checkpoint/best.pth'),\n",
    "        'epoch': epoch,\n",
    "        'loss': best_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, training_path)\n",
    "else:\n",
    "    checkpoint = torch.load(training_path)\n",
    "    if checkpoint['loss'] > best_val_loss:\n",
    "        print('best model updated')\n",
    "        checkpoint = {\n",
    "            'model': torch.load('checkpoint/best.pth'),\n",
    "            'epoch': epoch,\n",
    "            'loss': best_val_loss\n",
    "        }\n",
    "        torch.save(checkpoint, training_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(train_loss_log, label='train loss')\n",
    "plt.plot(val_loss_log, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
